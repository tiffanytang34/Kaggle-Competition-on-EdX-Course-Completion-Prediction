{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define RandomForest416\nimport scipy.stats \n\nclass RandomForest416: \n    \"\"\"\n    This class implements the common sklearn model interface (has a fit and predict function).\n    \n    A random forest is a collection of decision trees that are trained on random subsets of the \n    dataset. When predicting the value for an example, takes a majority vote from the trees.\n    \"\"\"\n    \n    def __init__(self, num_trees, max_depth=None):\n        \"\"\"\n        Constructs a RandomForest416 that uses the given numbner of trees, each with a \n        max depth of max_depth.\n        \"\"\"\n        # the self._trees object is a list of models, you can use it in the next function to loop over\n        # and fit the models one by one\n        self._trees = [\n            DecisionTreeClassifier(max_depth=max_depth) \n            for i in range(num_trees)\n        ]\n        \n    def fit(self, X, y):\n        \"\"\"\n        Takes an input dataset X and a series of targets y and trains the RandomForest416.\n        \n        Each tree will be trained on a random sample of the data that samples the examples\n        uniformly at random (with replacement). Each random dataset will have the same number\n        of examples as the original dataset, but some examples may be missing or appear more \n        than once due to the random sampling with replacement.\n        \"\"\"    \n        for tree in self._trees:\n          index = np.random.randint(0, len(X), size = len(X))\n          sample = X.iloc[index]\n          target = y.iloc[index]\n          tree.fit(sample, target)\n        \n            \n    def predict(self, X):\n        \"\"\"\n        Takes an input dataset X and returns the predictions for each example in X.\n        \"\"\"\n        \n        # Builds up a 2d array with n rows and T columns\n        # where n is the number of points to classify and T is the number of trees\n        predictions = np.zeros((len(X), len(self._trees)))\n        for i, tree in enumerate(self._trees):\n            # Make predictions using the current tree\n            preds = tree.predict(X)\n            \n            # Store those predictions in ith column of the 2d array\n            predictions[:, i] = preds\n            \n        # For each row of predictions, find the most frequent label (axis=1 means across columns)\n        return scipy.stats.mode(predictions, axis=1)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nedx_train = pd.read_csv('/kaggle/input/cse-stat-416-sum-20/edx_train.csv')\ndf_test = pd.read_csv('/kaggle/input/cse-stat-416-sum-20/edx_test.csv')\nto_save = df_test[['userid_DI']].copy()\nprint(len(df_test))\n# pre-process the data \ndel edx_train['course_id']\ndel edx_train['userid_DI']\ndel edx_train['registered']\ndel edx_train['start_time_DI']\ndel edx_train['last_event_DI']\n#del edx_train['certified']\nedx_train = pd.get_dummies(edx_train)\ndel df_test['course_id']\ndel df_test['userid_DI']\ndel df_test['registered']\ndel df_test['start_time_DI']\ndel df_test['last_event_DI']\ndf_test = pd.get_dummies(df_test)\n\nfeatures = list(edx_train.columns)\nfeatures.remove('certified')\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n\nrf = RandomForest416(5, max_depth=10)\nrf.fit(edx_train[features], edx_train['certified'])\n#pred_rf = rf.predict(validation_data[features])\n# The code to make the predictions on the test data \npredictions = rf.predict(df_test[features])\nnew_list = []\nfor item in predictions:\n    new_list.append(int(item))\n\n\nto_save.loc[:, 'certified'] = new_list\nto_save.to_csv('submission.csv', index=False)\nprint(to_save)\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}